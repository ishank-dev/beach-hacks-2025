{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 20000 in the FDA dataset\n",
      "Number of Document objects: 19472\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai.error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 75\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of Document objects: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sleep\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merror\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RateLimitError\n\u001b[1;32m     77\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai.error'"
     ]
    }
   ],
   "source": [
    "# chainlit run app.py -w\n",
    "\"\"\"\n",
    "PrescriptionIQ: A pharmacist assistant chatbot.\n",
    "This app uses Chainlit, LangChain, and Qdrant to answer pharmacy-related queries.\n",
    "It fetches related PubMed papers, suggests follow-up questions,\n",
    "and displays source details in a clickable, expandable format.\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------\n",
    "# Standard library imports\n",
    "# -------------------------\n",
    "import asyncio\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "\n",
    "# Environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Typing for function signatures\n",
    "from typing import Any, List, Optional\n",
    "\n",
    "# Bioinformatics\n",
    "from Bio import Entrez, Medline\n",
    "\n",
    "# -------------------------\n",
    "# Chainlit & LangChain imports\n",
    "# -------------------------\n",
    "import chainlit as cl\n",
    "from chainlit.types import AskFileResponse\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.evaluation import StringEvaluator\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.smith import RunEvalConfig, run_on_dataset\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.callbacks.tracers.evaluation import EvaluatorCallbackHandler\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
    "\n",
    "# -------------------------\n",
    "# Vector storage & Document Loading\n",
    "# -------------------------\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from qdrant_client import QdrantClient, AsyncQdrantClient\n",
    "\n",
    "# -------------------------\n",
    "# Custom Evaluations\n",
    "# -------------------------\n",
    "from custom_eval import PharmAssistEvaluator, HarmfulnessEvaluator, AIDetectionEvaluator\n",
    "\n",
    "# -------------------------\n",
    "# LangSmith Client\n",
    "# -------------------------\n",
    "from langsmith import Client\n",
    "langsmith_client = Client()\n",
    "\n",
    "# -------------------------\n",
    "# Load Environment Variables\n",
    "# -------------------------\n",
    "load_dotenv()\n",
    "\n",
    "# -------------------------\n",
    "# System Prompt & Message Setup\n",
    "# -------------------------\n",
    "system_template = \"\"\"\n",
    "You are an AI assistant for pharmacists and pharmacy students.\n",
    "Use the context provided to answer the user's question.\n",
    "\n",
    "If you don't have enough information, say soâ€”do not fabricate an answer.\n",
    "\n",
    "Always include a **SOURCES** section at the end of your response, referencing the documents used.\n",
    "\n",
    "Example response format:\n",
    "**Answer:**\n",
    "<your answer here>\n",
    "\n",
    "**SOURCES:**\n",
    "Source 1, Source 2, etc.\n",
    "\n",
    "Begin!\n",
    "----------------\n",
    "{summaries}\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "\n",
    "# Global Qdrant vector store reference\n",
    "qdrant_vectorstore = None\n",
    "\n",
    "# -------------------------\n",
    "# Function: Search Related Papers on PubMed\n",
    "# -------------------------\n",
    "async def search_related_papers(query, max_results=3):\n",
    "    \"\"\"\n",
    "    Search PubMed for papers related to the provided query and return a list of formatted strings.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # If you have an email, set it here:\n",
    "        Entrez.email = os.environ.get(\"ENTREZ_EMAIL\")\n",
    "        handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
    "        record = Entrez.read(handle)\n",
    "        handle.close()\n",
    "\n",
    "        id_list = record[\"IdList\"]\n",
    "        if not id_list:\n",
    "            return [\"No directly related papers found. Try broadening your search query.\"]\n",
    "\n",
    "        handle = Entrez.efetch(db=\"pubmed\", id=id_list, rettype=\"medline\", retmode=\"text\")\n",
    "        records = Medline.parse(handle)\n",
    "\n",
    "        related_papers = []\n",
    "        for record in records:\n",
    "            title = record.get(\"TI\", \"\")\n",
    "            authors = \", \".join(record.get(\"AU\", []))\n",
    "            citation = f\"{authors}. {title}. {record.get('SO', '')}\"\n",
    "            url = f\"https://pubmed.ncbi.nlm.nih.gov/{record['PMID']}/\"\n",
    "            related_papers.append(f\"[{citation}]({url})\")\n",
    "\n",
    "        if not related_papers:\n",
    "            return [\"No directly related papers found. Try broadening your search query.\"]\n",
    "        return related_papers\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while searching for related papers: {e}\")\n",
    "        return [\"An error occurred while searching for related papers. Please try again later.\"]\n",
    "\n",
    "# -------------------------\n",
    "# Function: Generate Related Questions\n",
    "# -------------------------\n",
    "async def generate_related_questions(retrieved_results, num_questions=2, max_tokens=50):\n",
    "    \"\"\"\n",
    "    Generate related questions based on retrieved document context.\n",
    "    \"\"\"\n",
    "    llm = OpenAI(temperature=0.7)\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"context\"],\n",
    "        template=\"Given the following context, generate {num_questions} related questions:\\n\\nContext: {context}\\n\\nQuestions:\",\n",
    "    )\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "    context = \" \".join([doc.page_content for doc in retrieved_results])\n",
    "    generated_questions = chain.run(\n",
    "        context=context, num_questions=num_questions, max_tokens=max_tokens\n",
    "    )\n",
    "\n",
    "    # Remove numbering from the generated questions\n",
    "    related_questions = [\n",
    "        question.split(\". \", 1)[-1]\n",
    "        for question in generated_questions.split(\"\\n\")\n",
    "        if question.strip()\n",
    "    ]\n",
    "    return related_questions\n",
    "\n",
    "# -------------------------\n",
    "# Function: Generate Answer\n",
    "# -------------------------\n",
    "async def generate_answer(query):\n",
    "    \"\"\"\n",
    "    Generate an answer using a conversational retrieval chain.\n",
    "    Return:\n",
    "      (formatted_answer, text_elements, related_question_actions, related_papers, source_actions, original_query)\n",
    "    \"\"\"\n",
    "    message_history = ChatMessageHistory()\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        output_key=\"answer\",\n",
    "        chat_memory=message_history,\n",
    "        return_messages=True,\n",
    "    )\n",
    "\n",
    "    chain = ConversationalRetrievalChain.from_llm(\n",
    "        ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, streaming=True),\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=qdrant_vectorstore.as_retriever(),\n",
    "        memory=memory,\n",
    "        return_source_documents=True,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        cb = cl.AsyncLangchainCallbackHandler()\n",
    "        feedback_callback = EvaluatorCallbackHandler(\n",
    "            evaluators=[\n",
    "                PharmAssistEvaluator(),\n",
    "                HarmfulnessEvaluator(),\n",
    "                AIDetectionEvaluator(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # 1) Call the chain\n",
    "        res = await chain.acall(query, callbacks=[cb, feedback_callback])\n",
    "        answer = res[\"answer\"]\n",
    "        source_documents = res[\"source_documents\"]\n",
    "\n",
    "        # 2) Remove any triple backticks to avoid code blocks & \"copy\" button\n",
    "        answer = answer.replace(\"```\", \"\")\n",
    "\n",
    "        # 3) Check if the LLM says \"I don't know...\"\n",
    "        if answer.lower().startswith(\"i don't know\") or answer.lower().startswith(\"i don't have enough information\"):\n",
    "            return answer, [], [], [], [], query\n",
    "\n",
    "        # 4) Format the answer as Markdown\n",
    "        formatted_answer = f\"**Answer:**\\n{answer}\"\n",
    "\n",
    "        # 5) Create source buttons for each source doc\n",
    "        source_actions = []\n",
    "        if source_documents:\n",
    "            for i, doc in enumerate(source_documents):\n",
    "                source_actions.append(\n",
    "                    cl.Action(\n",
    "                        name=\"show_source\",\n",
    "                        label=f\"Source {i+1}\",\n",
    "                        payload={\"source_content\": doc.page_content}\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # 6) Generate related question buttons\n",
    "        related_questions = await generate_related_questions(source_documents)\n",
    "        related_question_actions = [\n",
    "            cl.Action(\n",
    "                name=\"related_question\",\n",
    "                label=q.strip(),\n",
    "                payload={\"question\": q.strip()},\n",
    "            )\n",
    "            for q in related_questions if q.strip()\n",
    "        ]\n",
    "\n",
    "        # 7) Get related PubMed papers (markdown)\n",
    "        related_papers = await search_related_papers(query)\n",
    "\n",
    "        return formatted_answer, [], related_question_actions, related_papers, source_actions, query\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return (\n",
    "            \"An error occurred while processing your request. Please try again later.\",\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "            query,\n",
    "        )\n",
    "\n",
    "# -------------------------\n",
    "# Action Callback: Show Source Details\n",
    "# -------------------------\n",
    "@cl.action_callback(\"show_source\")\n",
    "async def on_show_source(action: cl.Action):\n",
    "    \"\"\"\n",
    "    When a source button is clicked, display the full source details.\n",
    "    \"\"\"\n",
    "    source_content = action.payload[\"source_content\"]\n",
    "    # Also remove triple backticks if present in the source\n",
    "    source_content = source_content.replace(\"```\", \"\")\n",
    "    await cl.Message(\n",
    "        content=f\"**Source Details:**\\n\\n{source_content}\",\n",
    "        author=\"PrescriptionIQ\"\n",
    "    ).send()\n",
    "\n",
    "# -------------------------\n",
    "# Action Callback: Related Question Selection\n",
    "# -------------------------\n",
    "@cl.action_callback(\"related_question\")\n",
    "async def on_related_question_selected(action: cl.Action):\n",
    "    \"\"\"\n",
    "    Handle a related question selection.\n",
    "    \"\"\"\n",
    "    question = action.payload[\"question\"]\n",
    "    await cl.Message(content=question, author=\"User\").send()\n",
    "\n",
    "    # Generate the new answer\n",
    "    answer, text_elements, related_question_actions, related_papers, source_actions, original_query = await generate_answer(question)\n",
    "\n",
    "    await cl.Message(content=answer, author=\"PrescriptionIQ\").send()\n",
    "\n",
    "    # If we have more related Qs, show them\n",
    "    if related_question_actions:\n",
    "        await cl.Message(\n",
    "            content=\"**Related Questions:**\",\n",
    "            actions=related_question_actions,\n",
    "            author=\"PrescriptionIQ\"\n",
    "        ).send()\n",
    "\n",
    "    # Show PubMed references if any\n",
    "    if related_papers:\n",
    "        papers_md = \"**Related Papers from PubMed:**\\n\" + \"\\n\".join(f\"- {paper}\" for paper in related_papers)\n",
    "        await cl.Message(content=papers_md, author=\"PrescriptionIQ\").send()\n",
    "\n",
    "    # Show the source expansion buttons\n",
    "    if source_actions:\n",
    "        await cl.Message(\n",
    "            content=\"**Sources:** Click to expand.\",\n",
    "            actions=source_actions,\n",
    "            author=\"PrescriptionIQ\"\n",
    "        ).send()\n",
    "\n",
    "# -------------------------\n",
    "# Action Callback: Ask Question Selection\n",
    "# -------------------------\n",
    "@cl.action_callback(\"ask_question\")\n",
    "async def on_question_selected(action: cl.Action):\n",
    "    \"\"\"\n",
    "    Respond to a selected question from the suggestions.\n",
    "    \"\"\"\n",
    "    question = action.payload[\"question\"]\n",
    "    await cl.Message(content=question, author=\"User\").send()\n",
    "\n",
    "    answer, text_elements, related_question_actions, related_papers, source_actions, original_query = await generate_answer(question)\n",
    "\n",
    "    await cl.Message(content=answer, author=\"PrescriptionIQ\").send()\n",
    "\n",
    "    if related_question_actions:\n",
    "        await cl.Message(\n",
    "            content=\"**Related Questions:**\",\n",
    "            actions=related_question_actions,\n",
    "            author=\"PrescriptionIQ\"\n",
    "        ).send()\n",
    "\n",
    "    if related_papers:\n",
    "        papers_md = \"**Related Papers from PubMed:**\\n\" + \"\\n\".join(f\"- {paper}\" for paper in related_papers)\n",
    "        await cl.Message(content=papers_md, author=\"PrescriptionIQ\").send()\n",
    "\n",
    "    if source_actions:\n",
    "        await cl.Message(\n",
    "            content=\"**Sources:** Click to expand.\",\n",
    "            actions=source_actions,\n",
    "            author=\"PrescriptionIQ\"\n",
    "        ).send()\n",
    "\n",
    "# -------------------------\n",
    "# on_chat_start\n",
    "# -------------------------\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    \"\"\"\n",
    "    Initialize the chatbot environment, load Qdrant data, and present initial suggestions.\n",
    "    \"\"\"\n",
    "    global qdrant_vectorstore\n",
    "\n",
    "    await cl.Message(content=\"**Loading PrescriptionIQ bot...**\").send()\n",
    "    await asyncio.sleep(2)\n",
    "\n",
    "    if qdrant_vectorstore is None:\n",
    "        embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        QDRANT_API_KEY = os.environ.get(\"QDRANT_API_KEY\")\n",
    "        QDRANT_CLUSTER_URL = os.environ.get(\"QDRANT_CLUSTER_URL\")\n",
    "        qdrant_client = AsyncQdrantClient(url=QDRANT_CLUSTER_URL, api_key=QDRANT_API_KEY, timeout=60)\n",
    "        response = await qdrant_client.get_collections()\n",
    "        collection_names = [collection.name for collection in response.collections]\n",
    "\n",
    "        if \"fda_drugs\" not in collection_names:\n",
    "            print(\"Collection 'fda_drugs' is not present.\")\n",
    "            # Download data\n",
    "            url = \"https://download.open.fda.gov/drug/label/drug-label-0001-of-0012.json.zip\"\n",
    "            resp = requests.get(url)\n",
    "            zip_file = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "            json_file = zip_file.open(zip_file.namelist()[0])\n",
    "            data = json.load(json_file)\n",
    "\n",
    "            df = pd.json_normalize(data[\"results\"])\n",
    "\n",
    "            metadata_fields = [\n",
    "                \"openfda.brand_name\",\n",
    "                \"openfda.generic_name\",\n",
    "                \"openfda.manufacturer_name\",\n",
    "                \"openfda.product_type\",\n",
    "                \"openfda.route\",\n",
    "                \"openfda.substance_name\",\n",
    "                \"openfda.rxcui\",\n",
    "                \"openfda.spl_id\",\n",
    "                \"openfda.package_ndc\",\n",
    "            ]\n",
    "            text_fields = [\n",
    "                \"description\",\n",
    "                \"indications_and_usage\",\n",
    "                \"contraindications\",\n",
    "                \"warnings\",\n",
    "                \"adverse_reactions\",\n",
    "                \"dosage_and_administration\",\n",
    "            ]\n",
    "\n",
    "            df[text_fields] = df[text_fields].fillna(\"\")\n",
    "            df[\"content\"] = df[text_fields].apply(lambda x: \" \".join(x.astype(str)), axis=1)\n",
    "\n",
    "            loader = DataFrameLoader(df, page_content_column=\"content\")\n",
    "            drug_docs = loader.load()\n",
    "\n",
    "            for doc, row in zip(drug_docs, df.to_dict(orient=\"records\")):\n",
    "                md = {}\n",
    "                for f in metadata_fields:\n",
    "                    val = row.get(f)\n",
    "                    if isinstance(val, list):\n",
    "                        val = \", \".join(str(v) for v in val if pd.notna(v))\n",
    "                    elif pd.isna(val):\n",
    "                        val = \"Not Available\"\n",
    "                    md[f] = val\n",
    "                doc.metadata = md\n",
    "\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "            split_drug_docs = text_splitter.split_documents(drug_docs)\n",
    "\n",
    "            qdrant_vectorstore = await cl.make_async(Qdrant.from_documents)(\n",
    "                split_drug_docs,\n",
    "                embedding_model,\n",
    "                url=QDRANT_CLUSTER_URL,\n",
    "                api_key=QDRANT_API_KEY,\n",
    "                collection_name=\"fda_drugs\",\n",
    "            )\n",
    "        else:\n",
    "            print(\"Collection 'fda_drugs' is present.\")\n",
    "            qdrant_vectorstore = await cl.make_async(Qdrant.construct_instance)(\n",
    "                texts=[\"\"],\n",
    "                embedding=embedding_model,\n",
    "                url=QDRANT_CLUSTER_URL,\n",
    "                api_key=QDRANT_API_KEY,\n",
    "                collection_name=\"fda_drugs\",\n",
    "            )\n",
    "\n",
    "    # Suggested questions\n",
    "    potential_questions = [\n",
    "        \"What should I be careful of when taking Metformin?\",\n",
    "        \"What are the contraindications of Aspirin?\",\n",
    "        \"Are there low-cost alternatives to branded Aspirin available over-the-counter?\",\n",
    "        \"What precautions should I take if I'm pregnant or nursing while on Lipitor?\",\n",
    "        \"Should Lipitor be taken at a specific time of day, and does it need to be taken with food?\",\n",
    "        \"What is the recommended dose of Aspirin?\",\n",
    "        \"Can older people take beta blockers?\",\n",
    "        \"How do beta blockers work?\",\n",
    "        \"Can beta blockers be used for anxiety?\",\n",
    "        \"I am taking Aspirin, is it ok to take Glipizide?\",\n",
    "        \"Explain in simple terms how Metformin works?\",\n",
    "    ]\n",
    "    await cl.Message(\n",
    "        content=\"**Welcome to PrescriptionIQ!** Here are some potential questions you can ask:\",\n",
    "        actions=[\n",
    "            cl.Action(name=\"ask_question\", label=q, payload={\"question\": q})\n",
    "            for q in potential_questions\n",
    "        ],\n",
    "    ).send()\n",
    "    cl.user_session.set(\"potential_questions_shown\", True)\n",
    "\n",
    "# -------------------------\n",
    "# On Message: Free Text\n",
    "# -------------------------\n",
    "@cl.on_message\n",
    "async def main(message):\n",
    "    \"\"\"\n",
    "    Process free text user input and generate a formatted answer.\n",
    "    \"\"\"\n",
    "    query = message.content.strip()\n",
    "    if not query:\n",
    "        await cl.Message(content=\"Please enter a valid question.\", author=\"PrescriptionIQ\").send()\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        answer, text_elements, related_question_actions, related_papers, source_actions, original_query = await generate_answer(query)\n",
    "        if not answer:\n",
    "            answer = \"Sorry, I couldn't generate an answer. Please try rephrasing your question.\"\n",
    "\n",
    "        # Combine everything, remove any triple backticks if leftover\n",
    "        answer = answer.replace(\"```\", \"\")\n",
    "        final_msg = f\"{answer}\\n\\n---\\n*Your question: {original_query}*\"\n",
    "\n",
    "        await cl.Message(content=final_msg, elements=text_elements, author=\"PrescriptionIQ\").send()\n",
    "\n",
    "        if related_question_actions:\n",
    "            await cl.Message(\n",
    "                content=\"**Related Questions:**\",\n",
    "                actions=related_question_actions,\n",
    "                author=\"PrescriptionIQ\"\n",
    "            ).send()\n",
    "\n",
    "        if related_papers:\n",
    "            papers_md = \"**Related Papers from PubMed:**\\n\" + \"\\n\".join(f\"- {p}\" for p in related_papers)\n",
    "            await cl.Message(content=papers_md, author=\"PrescriptionIQ\").send()\n",
    "\n",
    "        if source_actions:\n",
    "            await cl.Message(\n",
    "                content=\"**Sources:** Click to expand.\",\n",
    "                actions=source_actions,\n",
    "                author=\"PrescriptionIQ\"\n",
    "            ).send()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        error_msg = \"An error occurred while processing your request. Please try again later.\"\n",
    "        await cl.Message(content=error_msg, author=\"PrescriptionIQ\").send()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
