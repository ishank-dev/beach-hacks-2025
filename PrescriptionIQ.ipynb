{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Environment Setup\n",
    "\n",
    "import asyncio\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from typing import Any, List, Optional\n",
    "\n",
    "from Bio import Entrez, Medline\n",
    "\n",
    "import chainlit as cl\n",
    "from chainlit.types import AskFileResponse\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.evaluation import StringEvaluator\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.smith import RunEvalConfig, run_on_dataset\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.callbacks.tracers.evaluation import EvaluatorCallbackHandler\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
    "\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from qdrant_client import QdrantClient, AsyncQdrantClient\n",
    "\n",
    "from custom_eval import PharmAssistEvaluator, HarmfulnessEvaluator, AIDetectionEvaluator\n",
    "\n",
    "from langsmith import Client\n",
    "langsmith_client = Client()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: System Prompt and Global Variables\n",
    "\n",
    "system_template = \"\"\"\n",
    "You are an AI assistant for pharmacists and pharmacy students.\n",
    "Use the context provided to answer the user's question.\n",
    "\n",
    "If you don't have enough information, say soâ€”do not fabricate an answer.\n",
    "\n",
    "Always include a **SOURCES** section at the end of your response, referencing the documents used.\n",
    "\n",
    "Example response format:\n",
    "**Answer:**\n",
    "<your answer here>\n",
    "\n",
    "**SOURCES:**\n",
    "Source 1, Source 2, etc.\n",
    "\n",
    "Begin!\n",
    "----------------\n",
    "{summaries}\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "\n",
    "# Global variable for Qdrant vector store\n",
    "qdrant_vectorstore = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Functions for PubMed Search and Related Questions\n",
    "\n",
    "async def search_related_papers(query, max_results=3):\n",
    "    \"\"\"\n",
    "    Search PubMed for papers related to the provided query and return a list of formatted references.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        Entrez.email = os.environ.get(\"ENTREZ_EMAIL\")  # Set your email if needed\n",
    "        handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
    "        record = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        id_list = record[\"IdList\"]\n",
    "        if not id_list:\n",
    "            return [\"No directly related papers found. Try broadening your search query.\"]\n",
    "        handle = Entrez.efetch(db=\"pubmed\", id=id_list, rettype=\"medline\", retmode=\"text\")\n",
    "        records = Medline.parse(handle)\n",
    "        related_papers = []\n",
    "        for r in records:\n",
    "            title = r.get(\"TI\", \"\")\n",
    "            authors = \", \".join(r.get(\"AU\", []))\n",
    "            citation = f\"{authors}. {title}. {r.get('SO', '')}\"\n",
    "            url = f\"https://pubmed.ncbi.nlm.nih.gov/{r['PMID']}/\"\n",
    "            related_papers.append(f\"[{citation}]({url})\")\n",
    "        if not related_papers:\n",
    "            return [\"No directly related papers found. Try broadening your search query.\"]\n",
    "        return related_papers\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while searching for related papers: {e}\")\n",
    "        return [\"An error occurred while searching for related papers. Please try again later.\"]\n",
    "\n",
    "async def generate_related_questions(retrieved_results, num_questions=2, max_tokens=50):\n",
    "    \"\"\"\n",
    "    Generate related questions based on the provided retrieved document context.\n",
    "    \"\"\"\n",
    "    from langchain_openai import OpenAI  # Ensure OpenAI is available\n",
    "    llm = OpenAI(temperature=0.7)\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"context\"],\n",
    "        template=\"Given the following context, generate {num_questions} related questions:\\n\\nContext: {context}\\n\\nQuestions:\",\n",
    "    )\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    context = \" \".join([doc.page_content for doc in retrieved_results])\n",
    "    generated_questions = chain.run(context=context, num_questions=num_questions, max_tokens=max_tokens)\n",
    "    related_questions = [\n",
    "        question.split(\". \", 1)[-1] for question in generated_questions.split(\"\\n\") if question.strip()\n",
    "    ]\n",
    "    return related_questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Function to Generate Answer\n",
    "\n",
    "async def generate_answer(query):\n",
    "    \"\"\"\n",
    "    Generate an answer using a conversational retrieval chain.\n",
    "    Returns a tuple:\n",
    "      (formatted_answer, text_elements, related_question_actions, related_papers, source_actions, original_query)\n",
    "    \"\"\"\n",
    "    message_history = ChatMessageHistory()\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        output_key=\"answer\",\n",
    "        chat_memory=message_history,\n",
    "        return_messages=True,\n",
    "    )\n",
    "    chain = ConversationalRetrievalChain.from_llm(\n",
    "        ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, streaming=True),\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=qdrant_vectorstore.as_retriever(),\n",
    "        memory=memory,\n",
    "        return_source_documents=True,\n",
    "    )\n",
    "    try:\n",
    "        cb = cl.AsyncLangchainCallbackHandler()\n",
    "        feedback_callback = EvaluatorCallbackHandler(\n",
    "            evaluators=[\n",
    "                PharmAssistEvaluator(),\n",
    "                HarmfulnessEvaluator(),\n",
    "                AIDetectionEvaluator(),\n",
    "            ]\n",
    "        )\n",
    "        res = await chain.acall(query, callbacks=[cb, feedback_callback])\n",
    "        answer = res[\"answer\"]\n",
    "        source_docs = res[\"source_documents\"]\n",
    "\n",
    "        # Remove triple backticks to avoid code blocks (thus no copy button)\n",
    "        answer = answer.replace(\"```\", \"\")\n",
    "\n",
    "        if answer.lower().startswith(\"i don't know\") or answer.lower().startswith(\"i don't have enough information\"):\n",
    "            return answer, [], [], [], [], query\n",
    "\n",
    "        formatted_answer = f\"**Answer:**\\n{answer}\"\n",
    "\n",
    "        # Create clickable source buttons\n",
    "        source_actions = []\n",
    "        if source_docs:\n",
    "            for i, doc in enumerate(source_docs):\n",
    "                source_actions.append(\n",
    "                    cl.Action(\n",
    "                        name=\"show_source\",\n",
    "                        label=f\"Source {i+1}\",\n",
    "                        payload={\"source_content\": doc.page_content}\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # Generate related question buttons\n",
    "        related_questions = await generate_related_questions(source_docs)\n",
    "        related_question_actions = [\n",
    "            cl.Action(\n",
    "                name=\"related_question\",\n",
    "                label=q.strip(),\n",
    "                payload={\"question\": q.strip()}\n",
    "            )\n",
    "            for q in related_questions if q.strip()\n",
    "        ]\n",
    "\n",
    "        # Get related PubMed papers (as markdown formatted strings)\n",
    "        related_papers = await search_related_papers(query)\n",
    "\n",
    "        return formatted_answer, [], related_question_actions, related_papers, source_actions, query\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return (\n",
    "            \"An error occurred while processing your request. Please try again later.\",\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "            query,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Action Callbacks\n",
    "\n",
    "@cl.action_callback(\"show_source\")\n",
    "async def on_show_source(action: cl.Action):\n",
    "    \"\"\"\n",
    "    When a source button is clicked, display the full source details.\n",
    "    We use cl.Text with copyable=False to remove the copy button.\n",
    "    \"\"\"\n",
    "    source_content = action.payload[\"source_content\"].replace(\"```\", \"\")\n",
    "    text_elem = cl.Text(content=f\"**Source Details:**\\n\\n{source_content}\", copyable=False, markdown=True)\n",
    "    await cl.Message(elements=[text_elem], author=\"PrescriptionIQ\").send()\n",
    "\n",
    "@cl.action_callback(\"related_question\")\n",
    "async def on_related_question_selected(action: cl.Action):\n",
    "    \"\"\"\n",
    "    Handle a related question selection.\n",
    "    \"\"\"\n",
    "    question = action.payload[\"question\"]\n",
    "    user_elem = cl.Text(content=question, copyable=False, markdown=True)\n",
    "    await cl.Message(elements=[user_elem], author=\"User\").send()\n",
    "\n",
    "    ans, txt_elems, rel_q_actions, rel_papers, src_actions, orig_q = await generate_answer(question)\n",
    "    answer_elem = cl.Text(content=ans, copyable=False, markdown=True)\n",
    "    await cl.Message(elements=[answer_elem], author=\"PrescriptionIQ\").send()\n",
    "\n",
    "    if rel_q_actions:\n",
    "        rq_elem = cl.Text(content=\"**Related Questions:**\", copyable=False, markdown=True)\n",
    "        await cl.Message(elements=[rq_elem], actions=rel_q_actions, author=\"PrescriptionIQ\").send()\n",
    "\n",
    "    if rel_papers:\n",
    "        papers_md = \"**Related Papers from PubMed:**\\n\" + \"\\n\".join(f\"- {p}\" for p in rel_papers)\n",
    "        pm_elem = cl.Text(content=papers_md, copyable=False, markdown=True)\n",
    "        await cl.Message(elements=[pm_elem], author=\"PrescriptionIQ\").send()\n",
    "\n",
    "    if src_actions:\n",
    "        src_elem = cl.Text(content=\"**Sources:** Click to expand.\", copyable=False, markdown=True)\n",
    "        await cl.Message(elements=[src_elem], actions=src_actions, author=\"PrescriptionIQ\").send()\n",
    "\n",
    "@cl.action_callback(\"ask_question\")\n",
    "async def on_question_selected(action: cl.Action):\n",
    "    \"\"\"\n",
    "    Respond to a selected question from the suggestions.\n",
    "    \"\"\"\n",
    "    question = action.payload[\"question\"]\n",
    "    user_elem = cl.Text(content=question, copyable=False, markdown=True)\n",
    "    await cl.Message(elements=[user_elem], author=\"User\").send()\n",
    "\n",
    "    ans, txt_elems, rel_q_actions, rel_papers, src_actions, orig_q = await generate_answer(question)\n",
    "    answer_elem = cl.Text(content=ans, copyable=False, markdown=True)\n",
    "    await cl.Message(elements=[answer_elem], author=\"PrescriptionIQ\").send()\n",
    "\n",
    "    if rel_q_actions:\n",
    "        rq_elem = cl.Text(content=\"**Related Questions:**\", copyable=False, markdown=True)\n",
    "        await cl.Message(elements=[rq_elem], actions=rel_q_actions, author=\"PrescriptionIQ\").send()\n",
    "\n",
    "    if rel_papers:\n",
    "        papers_md = \"**Related Papers from PubMed:**\\n\" + \"\\n\".join(f\"- {p}\" for p in rel_papers)\n",
    "        pm_elem = cl.Text(content=papers_md, copyable=False, markdown=True)\n",
    "        await cl.Message(elements=[pm_elem], author=\"PrescriptionIQ\").send()\n",
    "\n",
    "    if src_actions:\n",
    "        src_elem = cl.Text(content=\"**Sources:** Click to expand.\", copyable=False, markdown=True)\n",
    "        await cl.Message(elements=[src_elem], actions=src_actions, author=\"PrescriptionIQ\").send()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: on_chat_start Callback\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    \"\"\"\n",
    "    Initialize the chatbot environment, load Qdrant data, and present initial suggested questions.\n",
    "    \"\"\"\n",
    "    global qdrant_vectorstore\n",
    "    loading_elem = cl.Text(content=\"**Loading PrescriptionIQ bot...**\", copyable=False, markdown=True)\n",
    "    await cl.Message(elements=[loading_elem]).send()\n",
    "    await asyncio.sleep(2)\n",
    "\n",
    "    if qdrant_vectorstore is None:\n",
    "        embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        QDRANT_API_KEY = os.environ.get(\"QDRANT_API_KEY\")\n",
    "        QDRANT_CLUSTER_URL = os.environ.get(\"QDRANT_CLUSTER_URL\")\n",
    "        qdrant_client = AsyncQdrantClient(url=QDRANT_CLUSTER_URL, api_key=QDRANT_API_KEY, timeout=60)\n",
    "        response = await qdrant_client.get_collections()\n",
    "        collection_names = [c.name for c in response.collections]\n",
    "\n",
    "        if \"fda_drugs\" not in collection_names:\n",
    "            print(\"Collection 'fda_drugs' is not present.\")\n",
    "            url = \"https://download.open.fda.gov/drug/label/drug-label-0001-of-0012.json.zip\"\n",
    "            resp = requests.get(url)\n",
    "            zip_file = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "            json_file = zip_file.open(zip_file.namelist()[0])\n",
    "            data = json.load(json_file)\n",
    "            df = pd.json_normalize(data[\"results\"])\n",
    "\n",
    "            metadata_fields = [\n",
    "                \"openfda.brand_name\",\n",
    "                \"openfda.generic_name\",\n",
    "                \"openfda.manufacturer_name\",\n",
    "                \"openfda.product_type\",\n",
    "                \"openfda.route\",\n",
    "                \"openfda.substance_name\",\n",
    "                \"openfda.rxcui\",\n",
    "                \"openfda.spl_id\",\n",
    "                \"openfda.package_ndc\",\n",
    "            ]\n",
    "            text_fields = [\n",
    "                \"description\",\n",
    "                \"indications_and_usage\",\n",
    "                \"contraindications\",\n",
    "                \"warnings\",\n",
    "                \"adverse_reactions\",\n",
    "                \"dosage_and_administration\",\n",
    "            ]\n",
    "            df[text_fields] = df[text_fields].fillna(\"\")\n",
    "            df[\"content\"] = df[text_fields].apply(lambda x: \" \".join(x.astype(str)), axis=1)\n",
    "\n",
    "            loader = DataFrameLoader(df, page_content_column=\"content\")\n",
    "            drug_docs = loader.load()\n",
    "\n",
    "            for doc, row in zip(drug_docs, df.to_dict(orient=\"records\")):\n",
    "                md = {}\n",
    "                for f in metadata_fields:\n",
    "                    val = row.get(f)\n",
    "                    if isinstance(val, list):\n",
    "                        val = \", \".join(str(v) for v in val if pd.notna(v))\n",
    "                    elif pd.isna(val):\n",
    "                        val = \"Not Available\"\n",
    "                    md[f] = val\n",
    "                doc.metadata = md\n",
    "\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "            split_drug_docs = text_splitter.split_documents(drug_docs)\n",
    "\n",
    "            qdrant_vectorstore = await cl.make_async(Qdrant.from_documents)(\n",
    "                split_drug_docs,\n",
    "                embedding_model,\n",
    "                url=QDRANT_CLUSTER_URL,\n",
    "                api_key=QDRANT_API_KEY,\n",
    "                collection_name=\"fda_drugs\",\n",
    "            )\n",
    "        else:\n",
    "            print(\"Collection 'fda_drugs' is present.\")\n",
    "            qdrant_vectorstore = await cl.make_async(Qdrant.construct_instance)(\n",
    "                texts=[\"\"],\n",
    "                embedding=embedding_model,\n",
    "                url=QDRANT_CLUSTER_URL,\n",
    "                api_key=QDRANT_API_KEY,\n",
    "                collection_name=\"fda_drugs\",\n",
    "            )\n",
    "\n",
    "    potential_questions = [\n",
    "        \"What should I be careful of when taking Metformin?\",\n",
    "        \"What are the contraindications of Aspirin?\",\n",
    "        \"Are there low-cost alternatives to branded Aspirin available over-the-counter?\",\n",
    "        \"What precautions should I take if I'm pregnant or nursing while on Lipitor?\",\n",
    "        \"Should Lipitor be taken at a specific time of day, and does it need to be taken with food?\",\n",
    "        \"What is the recommended dose of Aspirin?\",\n",
    "        \"Can older people take beta blockers?\",\n",
    "        \"How do beta blockers work?\",\n",
    "        \"Can beta blockers be used for anxiety?\",\n",
    "        \"I am taking Aspirin, is it ok to take Glipizide?\",\n",
    "        \"Explain in simple terms how Metformin works?\",\n",
    "    ]\n",
    "    welcome_elem = cl.Text(content=\"**Welcome to PrescriptionIQ!** Here are some potential questions you can ask:\", copyable=False, markdown=True)\n",
    "    await cl.Message(\n",
    "        elements=[welcome_elem],\n",
    "        actions=[cl.Action(name=\"ask_question\", label=q, payload={\"question\": q}) for q in potential_questions],\n",
    "    ).send()\n",
    "    cl.user_session.set(\"potential_questions_shown\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: on_message Callback\n",
    "\n",
    "@cl.on_message\n",
    "async def main(message):\n",
    "    \"\"\"\n",
    "    Process free text user input and generate a formatted answer.\n",
    "    \"\"\"\n",
    "    query = message.content.strip()\n",
    "    if not query:\n",
    "        no_query_elem = cl.Text(content=\"Please enter a valid question.\", copyable=False, markdown=True)\n",
    "        await cl.Message(elements=[no_query_elem], author=\"PrescriptionIQ\").send()\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        answer, txt_elems, rel_q_actions, rel_papers, src_actions, orig_q = await generate_answer(query)\n",
    "        if not answer:\n",
    "            answer = \"Sorry, I couldn't generate an answer. Please try rephrasing your question.\"\n",
    "\n",
    "        answer = answer.replace(\"```\", \"\")\n",
    "        final_msg = f\"{answer}\\n\\n---\\n*Your question: {orig_q}*\"\n",
    "        answer_elem = cl.Text(content=final_msg, copyable=False, markdown=True)\n",
    "        await cl.Message(elements=[answer_elem], author=\"PrescriptionIQ\").send()\n",
    "\n",
    "        if rel_q_actions:\n",
    "            rq_elem = cl.Text(content=\"**Related Questions:**\", copyable=False, markdown=True)\n",
    "            await cl.Message(elements=[rq_elem], actions=rel_q_actions, author=\"PrescriptionIQ\").send()\n",
    "\n",
    "        if rel_papers:\n",
    "            papers_md = \"**Related Papers from PubMed:**\\n\" + \"\\n\".join(f\"- {p}\" for p in rel_papers)\n",
    "            pm_elem = cl.Text(content=papers_md, copyable=False, markdown=True)\n",
    "            await cl.Message(elements=[pm_elem], author=\"PrescriptionIQ\").send()\n",
    "\n",
    "        if src_actions:\n",
    "            src_elem = cl.Text(content=\"**Sources:** Click to expand.\", copyable=False, markdown=True)\n",
    "            await cl.Message(elements=[src_elem], actions=src_actions, author=\"PrescriptionIQ\").send()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        error_elem = cl.Text(content=\"An error occurred while processing your request. Please try again later.\", copyable=False, markdown=True)\n",
    "        await cl.Message(elements=[error_elem], author=\"PrescriptionIQ\").send()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-22 23:16:02 - 1 change detected\n",
      "2025-03-22 23:16:03 - 1 change detected\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!chainlit run PrescriptionIQ.py -w\n",
    "# chainlit run app.py -p 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D  # This import registers the 3D projection, no need to call it directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with your actual embeddings\n",
    "n_samples = 100\n",
    "embedding_dim = 768  # Example dimension, adjust as needed.\n",
    "embeddings = np.random.randn(n_samples, embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA to reduce to 2 dimensions\n",
    "pca2d = PCA(n_components=2)\n",
    "embeddings_2d = pca2d.fit_transform(embeddings)\n",
    "\n",
    "# Create a 2D scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.7)\n",
    "plt.title(\"2D Visualization of Embeddings (PCA)\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA to reduce to 3 dimensions\n",
    "pca3d = PCA(n_components=3)\n",
    "embeddings_3d = pca3d.fit_transform(embeddings)\n",
    "\n",
    "# Create a 3D scatter plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(embeddings_3d[:, 0], embeddings_3d[:, 1], embeddings_3d[:, 2], alpha=0.7)\n",
    "ax.set_title(\"3D Visualization of Embeddings (PCA)\")\n",
    "ax.set_xlabel(\"Principal Component 1\")\n",
    "ax.set_ylabel(\"Principal Component 2\")\n",
    "ax.set_zlabel(\"Principal Component 3\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
